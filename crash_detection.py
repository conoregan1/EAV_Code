import pandas as pd
import numpy as np
from datetime import datetime
import os
from text_to_excel import process_data_file  # Import the process_data_file function


# Thresholds for small and large crashes
SMALL_CRASH_THRESHOLD = 2.0  # Example threshold for small crashes
LARGE_CRASH_THRESHOLD = 5.0  # Example threshold for large crashes
COOLDOWN_TIME = 1.0  # Time in seconds to wait after a crash before detecting another

def normalize_acceleration(df):
    """
    Normalize the acceleration data using roll, pitch, and yaw angles to remove the influence of Earth's gravity.
    """
    # Convert roll, pitch, and yaw from degrees to radians
    roll = np.radians(df['Roll'].values)  # Convert to NumPy array
    pitch = np.radians(df['Pitch'].values)  # Convert to NumPy array
    yaw = np.radians(df['Yaw'].values)  # Convert to NumPy array

    # Initialize arrays to store normalized acceleration data
    x_norm = np.zeros_like(roll)
    y_norm = np.zeros_like(roll)
    z_norm = np.zeros_like(roll)

    # Gravity vector in the global frame (Earth's frame)
    gravity_global = np.array([0, 0, 9.81])  # Assuming z-axis is up

    # Loop through each row and compute the normalized acceleration
    for i in range(len(roll)):
        # Create rotation matrices for the current row
        R_x = np.array([[1, 0, 0],
                        [0, np.cos(roll[i]), -np.sin(roll[i])],
                        [0, np.sin(roll[i]), np.cos(roll[i])]])

        R_y = np.array([[np.cos(pitch[i]), 0, np.sin(pitch[i])],
                        [0, 1, 0],
                        [-np.sin(pitch[i]), 0, np.cos(pitch[i])]])

        R_z = np.array([[np.cos(yaw[i]), -np.sin(yaw[i]), 0],
                        [np.sin(yaw[i]), np.cos(yaw[i]), 0],
                        [0, 0, 1]])

        # Combine rotation matrices (order: Z -> Y -> X)
        R = R_z @ R_y @ R_x  # Matrix multiplication

        # Rotate the gravity vector into the sensor's local frame
        gravity_local = R.T @ gravity_global  # Transpose of R to rotate global to local

        # Subtract the gravity component from the raw acceleration
        accel_local = np.array([df['x-axis'].iloc[i], df['y-axis'].iloc[i], df['z-axis'].iloc[i]])
        accel_normalized = accel_local - gravity_local

        # Store normalized acceleration data
        x_norm[i] = accel_normalized[0]
        y_norm[i] = accel_normalized[1]
        z_norm[i] = accel_normalized[2]

    # Add normalized acceleration data to the DataFrame
    df['x-axis_norm'] = x_norm
    df['y-axis_norm'] = y_norm
    df['z-axis_norm'] = z_norm

    return df

def detect_crashes(df, small_threshold, large_threshold, cooldown_time):
    """
    Detect small and large crashes based on normalized acceleration data.
    Returns:
        - small_crashes: List of tuples (time, acceleration) for small crashes.
        - large_crashes: List of tuples (time, acceleration) for large crashes.
    """
    small_crashes = []
    large_crashes = []
    last_crash_time = -cooldown_time  # Initialize to ensure the first crash is detected

    for index, row in df.iterrows():
        time = row['Time']
        accel_norm = np.sqrt(row['x-axis_norm']**2 + row['y-axis_norm']**2 + row['z-axis_norm']**2)

        # Check if enough time has passed since the last crash
        if time - last_crash_time >= cooldown_time:
            if accel_norm > large_threshold:
                large_crashes.append((time, accel_norm))  # Store time and acceleration as a tuple
                last_crash_time = time
            elif accel_norm > small_threshold:
                small_crashes.append((time, accel_norm))  # Store time and acceleration as a tuple
                last_crash_time = time

    return small_crashes, large_crashes

def main():
    # Specify the path to the data.txt file on the SD card
    data_file_path = 'D:/data.txt'  # Update this path to the actual location of your data.txt file

    # Specify the output directory (optional)
    output_directory = 'C:/Users/44753/Downloads/EAV_data/'  # Update this to your desired directory

    # Step 1: Run the text_to_excel script to process the data and save it to a CSV file
    process_data_file(data_file_path, output_directory)

    # Step 2: Load the CSV file generated by the text_to_excel script
    current_date = datetime.now().strftime('%Y-%m-%d')
    csv_file_path = os.path.join(output_directory, f'{current_date}.csv')
    df = pd.read_csv(csv_file_path)

    # Step 3: Normalize the acceleration data
    df = normalize_acceleration(df)

    # Print all normalized acceleration values for verification
    #print("Normalized Acceleration Values:")
    #print(df[['Time', 'x-axis_norm', 'y-axis_norm', 'z-axis_norm']].to_string(index=False))

    # Step 4: Detect crashes
    small_crashes, large_crashes = detect_crashes(df, SMALL_CRASH_THRESHOLD, LARGE_CRASH_THRESHOLD, COOLDOWN_TIME)

    # Step 5: Output results
    print(f"Number of small crashes: {len(small_crashes)}")
    print(f"Times of small crashes: {small_crashes}")
    print(f"Number of large crashes: {len(large_crashes)}")
    print(f"Times of large crashes: {large_crashes}")

if __name__ == "__main__":
    main()